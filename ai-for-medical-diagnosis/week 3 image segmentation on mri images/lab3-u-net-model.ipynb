{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model\n",
    "In this week's assignment, you'll be using a network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape when shown in a diagram like this (image from [U-net entry on wikipedia](https://en.wikipedia.org/wiki/U-Net)): \n",
    "\n",
    "<img src=\"images/U-net_example_wikipedia.png\" alt=\"U-net Image\" width=\"600\"/>\n",
    "\n",
    "U-nets are commonly used for image segmentation, which will be your task in the upcoming assignment. You won't actually need to implement U-Net in the assignment, but we wanted to give you an opportunity to gain some familiarity with this architecture here before you use it in the assignment. \n",
    "\n",
    "As you can see from the diagram, this architecture features a series of down-convolutions connected by max-pooling operations, followed by a series of up-convolutions connected by upsampling and concatenation operations. Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original [U-Net paper by Ronneberger et al. 2015](https://arxiv.org/abs/1505.04597). \n",
    "\n",
    "In this lab, you'll create a basic U-Net using Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 12:00:00.683094: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# Import the elements you'll need to build your U-Net\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Conv3DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "# Set the image shape to have the channels in the first dimension\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft dice loss function\n",
    "def soft_dice_loss(p, g):\n",
    "    return 1 - (2 * np.sum(np.dot(p, g))) / (np.sum(p*p) + np.sum(g*g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08979089790897898\n",
      "0.1562143671607753\n"
     ]
    }
   ],
   "source": [
    "# soft dice implementation\n",
    "import numpy as np\n",
    "p1 = np.array([0.3, 0.7, 0.3, 0.7, 0.9, 0.7, 0.3, 0.7, 0.3])\n",
    "g = np.array([0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0])\n",
    "\n",
    "p2 = np.array([0.5, 0.7, 0.5, 0.7, 0.9, 0.7, 0.5, 0.7, 0.5])\n",
    "\n",
    "l1 = soft_dice_loss(p1, g)\n",
    "l2 = soft_dice_loss(p2, g)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The \"Depth\" of your U-Net\n",
    "The \"depth\" of your U-Net is equal to the number of down-convolutions you will use. In the image above, the depth is 4 because there are 4 down-convolutions running down the left side including the very bottom of the U.\n",
    "\n",
    "For this exercise, you'll use a U-Net depth of 2, meaning you'll have 2 down-convolutions in your network. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Input Layer and its \"Depth\"\n",
    "\n",
    "In this lab and in the assignment, you will be doing 3D image segmentation, which is to say that, in addition to \"height\" and \"width\", your input layer will also have a \"length\". We are deliberately using the word \"length\" instead of \"depth\" here to describe the third spatial dimension of the input so as not to confuse it with the depth of the network as defined above.\n",
    "\n",
    "The shape of the input layer is `(num_channels, height, width, length)`, where `num_channels` you can think of like color channels in an image, `height`, `width` and `length` are just the size of the input.\n",
    "\n",
    "For the assignment, the values will be:\n",
    "- num_channels: 4\n",
    "- height: 160\n",
    "- width: 160\n",
    "- length: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4, 160, 160, 16) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an input layer tensor of the shape you'll use in the assignment\n",
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "input_layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tensor shape has a '?' as the very first dimension.  This will be the batch size. So the dimensions of the tensor are: (batch_size, num_channels, height, width, length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contracting (downward) Path \n",
    "Here you'll start by constructing the downward path in your network (the left side of the U-Net).  The `(height, width, length)` of the input gets smaller as you move down this path, and the number of channels increases.\n",
    "\n",
    "### 2.1 Depth 0\n",
    "\n",
    "By \"depth 0\" here, we're referring to the depth of the first down-convolution in the U-net.\n",
    "\n",
    "The number of filters is specified for each depth and for each layer within that depth.\n",
    "\n",
    "The formula to use for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=0$:\n",
    "$$filters_{0} = 32 \\times (2^{0}) = 32$$\n",
    "\n",
    "### 2.2 Layer 0\n",
    "There are two convolutional layers for each depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to create the first 3D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 12:00:07.767661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 160, 160, 16) dtype=float32 (created by layer 'conv3d')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Conv3D tensor with 32 filters\n",
    "down_depth_0_layer_0 = Conv3D(filters=32, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                              )(input_layer)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with 32 filters, the result you get above is a tensor with 32 channels.\n",
    "\n",
    "Run the next cell to add a relu activation to the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 160, 160, 16) dtype=float32 (created by layer 'activation')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a relu activation to layer 0 of depth 0\n",
    "down_depth_0_layer_0 = Activation('relu')(down_depth_0_layer_0)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Depth 0, Layer 1\n",
    "For layer 1 of depth 0, the formula for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth. \n",
    "- Notice that the '$\\times~2$' at the end of this expression isn't there for layer 0.\n",
    "\n",
    "\n",
    "So at depth $i=0$ for layer 1:\n",
    "$$filters_{0} = 32 \\times (2^{0}) \\times 2 = 64$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 160, 160, 16) dtype=float32 (created by layer 'activation_1')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Conv3D layer with 64 filters and add relu activation\n",
    "down_depth_0_layer_1 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_0)\n",
    "down_depth_0_layer_1 = Activation('relu')(down_depth_0_layer_1)\n",
    "down_depth_0_layer_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Max pooling\n",
    "Within the U-Net architecture, there is a max pooling operation after each of the down-convolutions (not including the last down-convolution at the bottom of the U). In general, this means you'll add max pooling after each down-convolution up to (but not including) the `depth - 1` down-convolution (since you started counting at 0). \n",
    "\n",
    "For this lab exercise:\n",
    "- The overall depth of the U-Net you're constructing is 2\n",
    "- So the bottom of your U is at a depth index of: $2-1 = 1$.\n",
    "- So far you've only defined the $depth=0$ down-convolutions, so the next thing to do is add max pooling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to add a max pooling operation to your U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 80, 80, 8) dtype=float32 (created by layer 'max_pooling3d')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a max pooling layer\n",
    "down_depth_0_layer_pool = MaxPooling3D(pool_size=(2,2,2))(down_depth_0_layer_1)\n",
    "down_depth_0_layer_pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Depth 1, Layer 0\n",
    "\n",
    "At depth 1, layer 0, the formula for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{1} = 32 \\times (2^{1}) = 64$$\n",
    "\n",
    "Run the next cell to add a Conv3D layer to your network with relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 80, 80, 8) dtype=float32 (created by layer 'activation_2')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D layer to your network with relu activation\n",
    "down_depth_1_layer_0 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_pool)\n",
    "down_depth_1_layer_0 = Activation('relu')(down_depth_1_layer_0)\n",
    "down_depth_1_layer_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Depth 1,  Layer 1\n",
    "\n",
    "For layer 1 of depth 1 the formula you'll use for number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth. \n",
    "- Notice that the '$\\times 2$' at the end of this expression isn't there for layer 0.\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{0} = 32 \\times (2^{1}) \\times 2 = 128$$\n",
    "\n",
    "Run the next cell to add another Conv3D with 128 filters to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 80, 80, 8) dtype=float32 (created by layer 'activation_3')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add another Conv3D with 128 filters to your network.\n",
    "down_depth_1_layer_1 = Conv3D(filters=128, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_1_layer_0)\n",
    "down_depth_1_layer_1 = Activation('relu')(down_depth_1_layer_1)\n",
    "down_depth_1_layer_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No max pooling at depth 1 (the bottom of the U)\n",
    "\n",
    "When you get to the \"bottom\" of the U-net, you don't need to apply max pooling after the convolutions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expanding  (upward) Path\n",
    "\n",
    "Now you'll work on the expanding path of the U-Net, (going up on the right side, when viewing the diagram).  The image's (height, width, length) all get larger in the expanding path.\n",
    "\n",
    "### 3.1 Depth 0, Up Sampling Layer 0\n",
    "\n",
    "You'll use a pool size of (2,2,2) for upsampling.\n",
    "- This is the default value for [tf.keras.layers.UpSampling3D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D)\n",
    "- As input to the upsampling at depth 1, you'll use the last layer of the downsampling.  In this case, it's the depth 1 layer 1.\n",
    "\n",
    "Run the next cell to add an upsampling operation to your network. \n",
    "Note that you're not adding any activation to this upsampling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 160, 160, 16) dtype=float32 (created by layer 'up_sampling3d')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an upsampling operation to your network\n",
    "up_depth_0_layer_0 = UpSampling3D(size=(2,2,2))(down_depth_1_layer_1)\n",
    "up_depth_0_layer_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Concatenate Upsampled Depth 0 with Downsampled Depth 0\n",
    "\n",
    "Now you'll apply a concatenation operation using the layers that are both at the same depth of 0.\n",
    "- up_depth_0_layer_0: shape is (?, 128, 160, 160, 16)\n",
    "- depth_0_layer_1: shape is (?, 64, 160, 160, 16)\n",
    "\n",
    "- Double check that both of these layers have the same height, width and length.\n",
    "- If they're the same, then they can be concatenated along axis 1 (the channel axis).\n",
    "- The (height, width, length) is (160, 160, 16) for both.\n",
    "\n",
    "Run the next cell to check that the layers you wish to concatenate have the same height, width and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 160, 160, 16), dtype=tf.float32, name=None), name='up_sampling3d/concat_2:0', description=\"created by layer 'up_sampling3d'\")\n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 160, 160, 16), dtype=tf.float32, name=None), name='activation_1/Relu:0', description=\"created by layer 'activation_1'\")\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of layers to concatenate\n",
    "print(up_depth_0_layer_0)\n",
    "print()\n",
    "print(down_depth_0_layer_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to add a concatenation operation to your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 192, 160, 160, 16) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a concatenation along axis 1\n",
    "up_depth_1_concat = concatenate([up_depth_0_layer_0,\n",
    "                                 down_depth_0_layer_1],\n",
    "                                axis=1)\n",
    "up_depth_1_concat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the upsampling layer had 128 channels, and the down-convolution layer had 64 channels so that when concatenated, the result has 128 + 64 = 192 channels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Up-convolution Layer 1\n",
    "\n",
    "The number of filters for this layer will be set to the number of channels in the down-convolution's layer 1 at the same depth of 0 (down_depth_0_layer_1).\n",
    "\n",
    "Run the next cell to have a look at the shape of the down-convolution depth 0 layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 160, 160, 16) dtype=float32 (created by layer 'activation_1')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the number of channels for `depth_0_layer_1` is 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of filters: {down_depth_0_layer_1.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 160, 160, 16) dtype=float32 (created by layer 'activation_4')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_1 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_concat)\n",
    "up_depth_1_layer_1 = Activation('relu')(up_depth_1_layer_1)\n",
    "up_depth_1_layer_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Up-convolution Depth 0, Layer 2\n",
    "\n",
    "At layer 2 of depth 0 in the up-convolution the next step will be to add another up-convolution. The number of filters you'll want to use for this next up-convolution will need to be equal to the number of filters in the down-convolution depth 0 layer 1.\n",
    "\n",
    "Run the next cell to remind yourself of the number of filters in down-convolution depth 0 layer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 160, 160, 16), dtype=tf.float32, name=None), name='activation_1/Relu:0', description=\"created by layer 'activation_1'\")\n",
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(down_depth_0_layer_1)\n",
    "print(f\"number of filters: {down_depth_0_layer_1.shape[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of channels / filters in `down_depth_0_layer_1` is 64."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to add a Conv3D up-convolution with 64 filters to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64, 160, 160, 16) dtype=float32 (created by layer 'activation_5')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_2 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_layer_1)\n",
    "up_depth_1_layer_2 = Activation('relu')(up_depth_1_layer_2)\n",
    "up_depth_1_layer_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Convolution\n",
    "\n",
    "For the final convolution, you will set the number of filters to be equal to the number of classes in your input data.\n",
    "\n",
    "In the assignment, you will be using data with 3 classes, namely:\n",
    "\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumor \n",
    "- 3: enhancing tumor\n",
    "\n",
    "Run the next cell to add a final Conv3D with 3 filters to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3, 160, 160, 16) dtype=float32 (created by layer 'conv3d_6')>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a final Conv3D with 3 filters to your network.\n",
    "final_conv = Conv3D(filters=3, #3 categories \n",
    "                    kernel_size=(1,1,1),\n",
    "                    padding='valid',\n",
    "                    strides=(1,1,1)\n",
    "                    )(up_depth_1_layer_2)\n",
    "final_conv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Activation for Final Convolution\n",
    "\n",
    "Run the next cell to add a sigmoid activation to your final convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3, 160, 160, 16) dtype=float32 (created by layer 'activation_6')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a sigmoid activation to your final convolution.\n",
    "final_activation = Activation('sigmoid')(final_conv)\n",
    "final_activation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create and Compile the Model\n",
    "\n",
    "In this example, you will be setting the loss and metrics to options that are pre-built in Keras.  However, in the assignment, you will implement better loss functions and metrics for evaluating the model's performance.\n",
    "\n",
    "Run the next cell to define and compile your model based on the architecture you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'TrackableSaver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define and compile your model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39;49minput_layer, outputs\u001b[39m=\u001b[39;49mfinal_activation)\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m),\n\u001b[1;32m      4\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m              )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/keras/engine/functional.py:137\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    136\u001b[0m generic_utils\u001b[39m.\u001b[39mvalidate_kwargs(kwargs, {})\n\u001b[0;32m--> 137\u001b[0m \u001b[39msuper\u001b[39;49m(Functional, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name\u001b[39m=\u001b[39;49mname, trainable\u001b[39m=\u001b[39;49mtrainable)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not created\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m# by tf.keras.Input()). In this case we need to clone the `Node` and\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# `KerasTensor` objects to mimic rebuilding a new model from new inputs.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/keras/engine/training.py:3331\u001b[0m, in \u001b[0;36msaver_with_op_caching\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   3329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3330\u001b[0m   saveables_cache \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentityWeakKeyDictionary()\n\u001b[0;32m-> 3331\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mTrackableSaver(\n\u001b[1;32m   3332\u001b[0m     tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mObjectGraphView(\n\u001b[1;32m   3333\u001b[0m         weakref\u001b[39m.\u001b[39mref(obj), saveables_cache\u001b[39m=\u001b[39msaveables_cache))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'TrackableSaver'"
     ]
    }
   ],
   "source": [
    "# Define and compile your model\n",
    "model = Model(inputs=input_layer, outputs=final_activation)\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Print out a summary of the model you created\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model you created\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! You've created your very own U-Net model architecture!\n",
    "Next, you'll check that you did everything correctly by comparing your model summary to the example model defined below.\n",
    "\n",
    "#### 4.2.1 Double Check Your Model\n",
    "\n",
    "To double check that you created the correct model, use a function that we've provided to create the same model, and check that the layers and the layer dimensions match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import predefined utilities\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute '_keras_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create a model using a predefined function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_2 \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39;49munet_model_3d(depth\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                                 loss_function\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical_crossentropy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                                 metrics\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mcategorical_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Workspace/Data Science/ai-for-medical-diagnosis/week 3 image segmentation on mri images/util.py:173\u001b[0m, in \u001b[0;36munet_model_3d\u001b[0;34m(loss_function, input_shape, pool_size, n_labels, initial_learning_rate, deconvolution, depth, n_base_filters, include_label_wise_dice_coefficients, metrics, batch_normalization, activation_name)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m# add levels with up-convolution or up-sampling\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m layer_depth \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(depth \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    170\u001b[0m     up_convolution \u001b[39m=\u001b[39m get_up_convolution(pool_size\u001b[39m=\u001b[39mpool_size,\n\u001b[1;32m    171\u001b[0m                                         deconvolution\u001b[39m=\u001b[39mdeconvolution,\n\u001b[1;32m    172\u001b[0m                                         n_filters\u001b[39m=\u001b[39m\n\u001b[0;32m--> 173\u001b[0m                                         current_layer\u001b[39m.\u001b[39;49m_keras_shape[\u001b[39m1\u001b[39m])(\n\u001b[1;32m    174\u001b[0m         current_layer)\n\u001b[1;32m    175\u001b[0m     concat \u001b[39m=\u001b[39m concatenate([up_convolution, levels[layer_depth][\u001b[39m1\u001b[39m]], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    176\u001b[0m     current_layer \u001b[39m=\u001b[39m create_convolution_block(\n\u001b[1;32m    177\u001b[0m         n_filters\u001b[39m=\u001b[39mlevels[layer_depth][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39m_keras_shape[\u001b[39m1\u001b[39m],\n\u001b[1;32m    178\u001b[0m         input_layer\u001b[39m=\u001b[39mconcat, batch_normalization\u001b[39m=\u001b[39mbatch_normalization)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute '_keras_shape'"
     ]
    }
   ],
   "source": [
    "# Create a model using a predefined function\n",
    "model_2 = util.unet_model_3d(depth=2,\n",
    "                                loss_function='categorical_crossentropy',\n",
    "                                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Print out a summary of the model created by the predefined function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_2\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model created by the predefined function\n",
    "model_2.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the model summary for the U-Net you created and compare it to the summary for the example model created by the predefined function you imported above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it for this exercise, we hope this have provided you with more insight into the network architecture you'll be working with in this week's assignment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc9ada5d02e0537e8935d15322f512dad980ab15d06f4ed986a164e7475ca677"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
